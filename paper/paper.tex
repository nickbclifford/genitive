%
% File acl2019.tex
%
%% Based on the style files for ACL 2018, NAACL 2018/19, which were
%% Based on the style files for ACL-2015, with some improvements
%%  taken from the NAACL-2016 style
%% Based on the style files for ACL-2014, which were, in turn,
%% based on ACL-2013, ACL-2012, ACL-2011, ACL-2010, ACL-IJCNLP-2009,
%% EACL-2009, IJCNLP-2008...
%% Based on the style files for EACL 2006 by 
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt,a4paper]{article}
\usepackage[hyperref]{acl2019}
\usepackage[utf8]{inputenc}
\usepackage[russian,english]{babel}
\usepackage{times}
\usepackage{latexsym}
\usepackage{amssymb}
\usepackage{multirow}
\usepackage{tipa}

\usepackage{url}

%\aclfinalcopy % Uncomment this line for the final submission
%\def\aclpaperid{***} %  Enter the acl Paper ID here

%\setlength\titlebox{5cm}
% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.

\newcommand\BibTeX{B\textsc{ib}\TeX}

\title{Instructions for ACL 2019 Proceedings}

\author{George Vallejo \\
  \texttt{gavallejo02@uchicago.edu} \\\And
  Nick Clifford \\
  \texttt{nclifford@uchicago.edu} \\}

\date{}

\begin{document}
\maketitle
\begin{abstract}
  Several features of human language can be described through rules,
  and natively speaking children of languages are cognizant of these rules, 
  even without formal instruction. Prior research has attempted to model
  such learning in children using connectionist neural networks for
  paradigms such as the English past tense. We investigate how a gradient-descent
  neural network could acquire the rules for declining Russian nouns into
  the genitive case for both singular and plural nouns in a similar fashion. 
  We also test whether two different NNs for the singular and plural numbers
  can model the learning of these rules in children better than a single
  NN by comparing the models' performance to that of native Russian-speaking children.

\end{abstract}

\section{Credits}

  This paper is an adaptation of the paper
  \emph{On Learning the Past Tenses of English Verbs} by D. E. Rumelhart and
  J. L. McClelland.

\section{Introduction}

Many features of natural languages, such as verb conjugation, noun case
declension, and agglutination behave in ways that can be described
by sets of rules. Being cognizant of these rules is an important aspect
of language acquisition in children, because awareness of these rules allows
them to utilize newly acquired vocabulary to express new concepts in the same
manner they may have used in a previous utterance. For example, the most common
ending used to express the past tense in English is -ed, as in ``I waited at home''.
Awareness of this rule would allow a child to additionally express ``I hunted at
the park'' after learning the verb ``hunt'' using the same ending.

However, it is also often the case that these rules have exceptions or other
irregularities. In English, ablaut is a source of several irregular verbs'
past tense forms. For example, the past tense of ``run'' is ``ran'', and
a child aware of the basic past tense rule may incorrectly express
``I runned to the park'' as a result, a phenomenon known as overgeneralizing.
This phemoenon is also important for learning, as the corrections the child
receives improve their understanding of the past tense, ultimately allowing
them to generalize the past tense for more verbs with greater accuracy.

Prior research has attempted to create neural networks to function as
language acquisition devices (LAD) in order to model how children acquire
the English past tense. Most notably, Rumelhart and McClelland (1986)
made use of a perceptron model to model the learning of English past
tense in three stages based on prior research into how children
acquire it, and obtained learning results that very closely
align with children's learning. We therefore investigate whether
the acquisition of the genitive case in Russian would yield similar results.

\subsection{Russian noun case morphology}

Grammatical cases are a system of marking nouns and noun modifiers in order
to indicate the noun (modifier)'s intended grammatical function in a sentence.
While historically English had grammatical cases, they survive in modern English
only through pronouns. Every pronoun in English has three different forms representing
three different cases. These are:

\begin{enumerate}
    \item Nominative: Marks the subject of a sentence: \emph{I} help him.
    \item Accusative: Marks the indirect object of a sentence: He helps \emph{me}.
    \item Genitive: Marks the possessor of a noun: \emph{My} book is great.
\end{enumerate}

Russian, being a member of the Slavic branch of the Indo-European languages,
has a fully functioning grammatical case system which is used for all nouns
unlike English. Nouns and noun modifiers in Russian inflect for case
by changing the ending of the word, and the exact manner by which an ending
changes depends on the ending, case, and number of the noun. Table 1 shows 
the different possible endings of the Russian nominative and genitive cases in 
the singular and plural. 

There are, of course, various irregularities in forming the genitive case
for certain nouns. Some nouns have suppletive roots, found only in the
plural form: for example, the noun \emph{\v{c}elovjek} (person) has the regular singular 
genitive form \emph{\v{c}elovjeka}. However, in the nominative plural, it becomes
\emph{ljudji}, and in the genitive plural \emph{ljudjej}, using an entirely different
noun stem for the plural cases.

The reason we chose the genitive case to study is because its formation,
much like the English past tense, is fairly regular in the singular; in a majority of cases,
the genitive form can be simply derived from the nominative by modifying the
noun's ending based on the table. We also chose it because the genitive plural,
in particular, tends to be more irregular. It is often the aspect of Russian
that is most difficult for learners of the language to comprehend, so
we wanted to investigate how a gradient-descent neural network would handle
acquiring the genitive case in singular and plural forms.

We also chose the genitive because it is a case that (with the exception of
indeclinable nouns, which we ignored for this paper) always changes the noun
in some way. This is contrasted with the accusative case, which can either
not change the noun, use the genitive form to represent the accusative, or 
use its own unique endings. Whichever scenario applies depends on not just 
the ending of the noun, but also its gender and animacy.

\begin{table}[t!]
\begin{center}
\begin{tabular}{|l|l|l}
\hline & \textbf{Singular} & \textbf{Plural} \\ \hline
\textbf{Nominative} & -a, -ja, -ija & -I\textbackslash, -i, -ii \\
\textbf{Genitive} & -I\textbackslash, -i, -ii & $\varnothing$, -', -ij \\ \hline
\textbf{Nominative} & $\varnothing$, -'/j, -ij & -I\textbackslash, -i, -ii, -je \\
\textbf{Genitive} & -a, -ja, -ija & -ov, -jej/jev, -ijev \\ \hline
\textbf{Nominative} & -o, -je & -a, -ja \\
\textbf{Genitive} & -a, -ja & $\varnothing$, -j, -jej \\ \hline
\textbf{Nominative} & -' & -i \\
\textbf{Genitive} & -i & -jej \\ \hline
\textbf{Nominative} & -mja & -mjena \\
\textbf{Genitive} & -mjeni & -mjon \\ \hline
\end{tabular}
\end{center}
\caption{\label{declension} Nominative and genitive endings for nouns with different endings, written with X-SAMPA. Note that the apostrophe ' is a palatalization character, corresponding to \foreignlanguage{russian}{ь} in Cyrillic. }
\end{table}

\section{Featural representation of Russian phonemes}

Rumelhart and McClelland (1986) made use of a scheme to encode
English phoneme units, known as Wickelphones and Wickelfeatures, described
in Wickelgren (1969). Wickelphones are phoneme units representing
each phone in a word as triples, which consist of the phoneme itself,
its predecessor to the left, and its successor on the right.
Wickelfeatures are a means of representing Wickelphones as distributed
patterns of activation by capturing one feature of the central phoneme,
one feature of the predecessor, and one feature of the successor.

The feature coding scheme we used to capture Russian phonemes did not
differ heavily from Rumelhart and McClelland's scheme. However, in order
to accomodate Russian's richer consonant inventory, we had to add an
extra dimension to the scheme to account for plain vs. palatalized
consonants, the latter of which are in abundance in Russian phonology.

In addition to accomodating Russian phonology for Wickelfeatures, we had to make some
decisions regards to what exact sounds are in Russian. Specifically,
the status of the close central unrounded vowel \textipa{/\textbari/} 
(written in Cyrillic as \foreignlanguage{russian}{ы}) as a separate 
vowel morpheme in Russian is a subject of heavy debate. Some linguists 
believe in a five-vowel analysis, meaning that the vowel \textipa{/\textbari/} 
is in complementary distribution with the close front unrounded vowel 
\textipa{/i/} (written in Cyrillic as \foreignlanguage{russian}{и}), 
such that the vowel phoneme \textipa{/i/} occurs after soft (i.e. 
palatalized) consonants, whereas the vowel phoneme \textipa{/\textbari/} 
occurs after hard (i.e. plain) consonants. Other linguists believe in a
six-vowel analysis, asserting \textipa{/\textbari/} as a separate phoneme.

Another set of phonemes with disputed status in Russian are palatalized
velar consonants (i.e. \textipa{/k\super j/}, \textipa{/g\super j/}, 
and \textipa{/x\super j/}) as well as the palatalized voiceless alveolar
sibilant affricate \textipa{/\t{ts}\super j/}. In most cases, the velar consonants
become soft when followed by front vowels (except in the case of a word
boundary between the consonant and vowel), and the affricate is generally
always hard. It is only in certain loanwords and foreign names that
the consonants may become palatalized in other contexts.

For the sake of our experiment, however, we have chosen to follow the
five-vowel analysis and not count the extra palatalized consonants
as Russian phonemes. The phonemic status of the vowel \textipa{/\textbari/}
is marginal, only occuring isolated in the verb \foreignlanguage{russian}{ыкать}
(to pronounce the sound \foreignlanguage{russian}{ы}) and in borrowed names
of places in Russia. By following the five-vowel analysis, we can account for
one less vowel, because \textipa{/\textbari/} and \textipa{/i/} are otherwise
in complementary distribution in all other environments. Likewise, because
the velar consonants are normally only palatalized following front vowels,
there is no need to account for such redundant information.

Table 2 shows the scheme that we used to categorize Russian phonemes
on five simple dimensions.

\begin{table*}[t!]
\centering
\begin{tabular}{cccccccccccccc}
    \multicolumn{2}{c}{} & \multicolumn{12}{c}{Place}\\\hline
    \multicolumn{2}{c}{} & \multicolumn{4}{c}{Front} & \multicolumn{4}{c}{Middle} & \multicolumn{4}{c}{Back}\\\hline
    \multicolumn{2}{c}{} & \multicolumn{2}{c}{Voiceless} & \multicolumn{2}{c}{Voiced} & \multicolumn{2}{c}{Voiceless} & \multicolumn{2}{c}{Voiced} & \multicolumn{2}{c}{Voiceless} & \multicolumn{2}{c}{Voiced}\\\hline
    \multicolumn{2}{c}{} & H & S & H & S & H & S & H & S & H & S & H & S\\\hline
    \multirow{2}{50px}{Interrupted} & Stop & p & p' & b & b' & t & t' & d & d' & k & - & g & -\\
    & Nasal & - & - & m & m' & - & - & n & n' & - & - & - & - \\
    \multirow{2}{50px}{Cont.Cons.} & Fricative & f & f' & v & v' & s & s' & z & z' & s\` & t\_s\textbackslash & z\` & -\\
                                        & Liq/Sem. & - & - & l & l' & t\_s & - & r & r' & x & - & - & j\\
    \multirow{2}{50px}{Vowel} & Close & - & - & i & - & - & - & - & - & - & - & u & -\\
                              & Open & - & - & e & - & - & - & a & - & - & - & o & -\\
\end{tabular}
\caption{Categorization of Russian phonemes on five dimensions.
All phonemes are written using X-SAMPA.}
\end{table*}

\section{Experimental setup}

To run our experiment, we first obtained a Russian word list, filtered the
word data, then preprocessed the data into a format that can be used by a
neural network model. We then trained our neural network models based on
our word data and evaluated the results. The procedure for these steps
is outlined in the subsections below.

\subsection{Collecting Russian nouns and declensions}

In order to train the neural network, we needed a list of Russian nouns
and their genitive singular and plural forms. For this, we scraped words
from Wiktionary. Wiktionary is an online, multilingual, and free project
to create a dictionary for all natural languages. These dictionary entries
often contain additional information about words in languages, such as verb
conjugations, example sentences, synonyms and antonyms, and most importantly,
noun declensions.

Every Russian noun with an entry on Wiktionary is accessible through the category
page \textbf{Category:Russian Nouns}. Using Wiktionary's MediaWiki API, we gathered
every noun in this category in batches of 500 (due to API limitations). For each
batch, we checked to make sure that the word only contained letters in the modern
Russian Cyrillic alphabet, because Wiktionary also has entries for Russian words
containing characters from different alphabets (e.g. \textbf{\foreignlanguage{russian}{QR-код}},
meaning ``QR code'') as well as alternate spellings of words containing archaic letters 
unused since the Russian spelling reform of 1918.

After performing this initial pruning, we then queried the API for each word's
entry in Wiktionary and attempted to extract its genitive singular and plural
forms from the declension table available in the entry. If either the singular
or plural genitive forms were missing from the table, the noun is discarded.
This can happen if a word is an indeclinable loanword or only exists in either
the singular or plural forms. We then save the word, its genitive singular and
plural forms into a wordlist, which will be consulted during the pre-processing
and training phases.

\subsection{Noun data pre-processing}

Before the noun data can be used as input to train the neural network, it must
first be converted into a representation usable by the model.

The first transformation that takes place is converting the noun forms'
Russian Cyrillic representation into a phonemic representation in X-SAMPA\@.
Because the Russian alphabet is much more phonemically consistent than English,
meaning it is possible to derive a word's phonemic representation by iterating
through its Cyrillic representation one letter at a time.

% TODO: explain this better
After being converted into X-SAMPA, each phoneme would then be converted into
its Wickelphone/Wickelfeature representations.

The Wickelfeatures would then be converted into arrays of activations for
certain features. 

\subsection{Neural network}

The basis of our neural network is a gradient-descent neural network powered by the
\emph{PyTorch} library. It uses a single linear transformation layer with the
input size being the number of Wickelfeatures that can be activated for,
and the output size being either 1 or 2 times the number of Wickelfeatures
that can be activated for, depending on whether the model is one of the
two smaller models learning individual genitive cases or the larger model
learning both genitive cases.

\textbf{Citations}: Citations within the text appear in parentheses
as~\cite{Gusfield:97} or, if the author's name appears in the text
itself, as Gusfield~\shortcite{Gusfield:97}.
Using the provided \LaTeX\ style, the former is accomplished using
{\small\verb|\cite|} and the latter with {\small\verb|\shortcite|} or {\small\verb|\newcite|}. Collapse multiple citations as in~\cite{Gusfield:97,Aho:72}; this is accomplished with the provided style using commas within the {\small\verb|\cite|} command, \emph{e.g.}, {\small\verb|\cite{Gusfield:97,Aho:72}|}. Append lowercase letters to the year in cases of ambiguities.  
 Treat double authors as
in~\cite{Aho:72}, but write as in~\cite{Chandra:81} when more than two
authors are involved. Collapse multiple citations as
in~\cite{Gusfield:97,Aho:72}. Also refrain from using full citations
as sentence constituents.

\section*{Acknowledgments}

The acknowledgments should go immediately before the references.  Do
not number the acknowledgments section. Do not include this section
when submitting your paper for review. \\

\noindent \textbf{Preparing References:} \\
Include your own bib file like this:
\verb|\bibliographystyle{acl_natbib}|
\verb|\bibliography{acl2019}| 

where \verb|acl2019| corresponds to a acl2019.bib file.
\bibliography{acl2019}
\bibliographystyle{acl_natbib}

\appendix

\section{Appendices}
\label{sec:appendix}
Appendices are material that can be read, and include lemmas, formulas, proofs, and tables that are not critical to the reading and understanding of the paper. 
Appendices should be \textbf{uploaded as supplementary material} when submitting the paper for review. Upon acceptance, the appendices come after the references, as shown here. Use
\verb|\appendix| before any appendix section to switch the section
numbering over to letters.

\end{document}
